# Use Python 3.8 Slim as the base image to keep the image size down
FROM python:3.8-slim

# Set the working directory in the container
WORKDIR /app

# Install Java, required for Spark
RUN apt-get update && \
    apt-get install -y default-jdk && \
    apt-get clean

# Set JAVA_HOME environment variable
ENV JAVA_HOME /usr/lib/jvm/default-java

# Copy the requirements file into the container and install Python dependencies
COPY requirements.txt /app/
RUN pip install --no-cache-dir -r requirements.txt

# Copy the rest of your application's code into the container
COPY . /app/

# Ensure the PostgreSQL JDBC driver jar is included in the image
COPY libs/postgresql-42.7.2.jar /app/libs/

# Specify the environment variable for the historic data path
# Note: This path is now within the Docker container, pointing to where you copied your data
ENV HISTORIC_DATA_PATH /app/data_sources/manual_data_collected/historic_data

# Command to run your application
CMD ["python", "etl_process/historic_data_to_sql.py"]
